{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae09330542cda4f7",
   "metadata": {},
   "source": [
    "# Example of Weave tracked evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67886ff7-8940-478f-af32-c147c65de5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following examples from https://github.com/wandb/weave/blob/master/docs/docs/tutorial-eval.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a8d06759245198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import weave\n",
    "from weave.scorers import MultiTaskBinaryClassificationF1\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64f59d1-5c38-4c28-859b-1c635118f648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = [\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\",\n",
    "\"Pounits are a bright green color and are more savory than sweet.\",\n",
    "\"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"]\n",
    "labels = [\n",
    "    {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},\n",
    "    {'fruit': 'pounits', 'color': 'bright green', 'flavor': 'savory'},\n",
    "    {'fruit': 'glowls', 'color': 'pale orange', 'flavor': 'sour and bitter'}\n",
    "]\n",
    "examples = [\n",
    "    {'id': '0', 'sentence': sentences[0], 'target': labels[0]},\n",
    "    {'id': '1', 'sentence': sentences[1], 'target': labels[1]},\n",
    "    {'id': '2', 'sentence': sentences[2], 'target': labels[2]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13c26be-b62d-4cfc-9d53-eed0ed3049b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weave version 0.51.35 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: bikashg.\n",
      "View Weave data at https://wandb.ai/bikashg-spencer-group/eval-example/weave\n"
     ]
    }
   ],
   "source": [
    "# We create a model class with one predict function.\n",
    "# All inputs, predictions and parameters are automatically captured for easy inspection.\n",
    "class ExtractFruitsModel(weave.Model):\n",
    "    model_name: str\n",
    "    prompt_template: str\n",
    "\n",
    "    @weave.op()\n",
    "    async def predict(self, sentence: str) -> dict:\n",
    "        client = openai.AsyncClient()\n",
    "\n",
    "        response = await client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": self.prompt_template.format(sentence=sentence)}\n",
    "            ],\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        if result is None:\n",
    "            raise ValueError(\"No response from model\")\n",
    "        parsed = json.loads(result)\n",
    "        return parsed\n",
    "\n",
    "# We call init to begin capturing data in the project, intro-example.\n",
    "weave.init('eval-example')\n",
    "\n",
    "# We create our model with our system prompt.\n",
    "model = ExtractFruitsModel(name='gpt-4-0125-preview',\n",
    "                        model_name='gpt-4-0125-preview',\n",
    "                        prompt_template='Extract fields (\"fruit\": <str>, \"color\": <str>, \"flavor\") from the following text, as json: {sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28702f2c-7e33-46ea-ae59-5ebf1e195a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/bikashg-spencer-group/eval-example/r/call/01956871-76ac-7613-8afe-a0b93919e3f5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get prediction on one single example as a test.\n",
    "await model.predict(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7512cbf9-cf1e-462d-81b6-cd745903ccec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T11:15:27.016924Z",
     "start_time": "2025-02-18T11:15:23.165351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'model_output' key for compatibility with older scorers. Please update scorers to use 'output' parameter.\n"
     ]
    }
   ],
   "source": [
    "### We define a scoring function to compare our model predictions with a ground truth label.\n",
    "@weave.op()\n",
    "def fruit_name_score(target: dict, output: dict) -> dict:\n",
    "    return {'correct': target['fruit'] == output['fruit']}\n",
    "\n",
    "# Finally, we run an evaluation of this model.\n",
    "# This will generate a prediction for each input example, and then score it with each scoring function.\n",
    "evaluation = weave.Evaluation(\n",
    "    name='fruit_eval',\n",
    "    dataset=examples, scorers=[MultiTaskBinaryClassificationF1(class_names=[\"fruit\", \"color\", \"flavor\"]), fruit_name_score],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9925058c-a100-4619-8542-4d71f553dad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MultiTaskBinaryClassificationF1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'fruit'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666666666666</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'color'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'flavor'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fruit_name_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666666666666</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0532805919647217</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'MultiTaskBinaryClassificationF1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'fruit'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m0.8\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.6666666666666666\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'color'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'flavor'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'fruit_name_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.6666666666666666\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m2.0532805919647217\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/bikashg-spencer-group/eval-example/r/call/01956871-7e1e-71d3-be5f-5f5f0244e47d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MultiTaskBinaryClassificationF1': {'fruit': {'f1': 0.8,\n",
       "   'precision': 0.6666666666666666,\n",
       "   'recall': 1.0},\n",
       "  'color': {'f1': 1.0, 'precision': 1.0, 'recall': 1.0},\n",
       "  'flavor': {'f1': 1.0, 'precision': 1.0, 'recall': 1.0}},\n",
       " 'fruit_name_score': {'correct': {'true_count': 2,\n",
       "   'true_fraction': 0.6666666666666666}},\n",
       " 'model_latency': {'mean': 2.0532805919647217}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(asyncio.run(evaluation.evaluate(model)))\n",
    "# if you're in a Jupyter Notebook, run:\n",
    "await evaluation.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef5916ddfc938e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c638db-07be-4d10-95f4-4ca38453280e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction with another model on the same dataset and using the same evaluation module (same scoring function)\n",
    "# We create our model with our system prompt.\n",
    "model_2 = ExtractFruitsModel(name='gpt-4o-mini',\n",
    "                        model_name='gpt-4o-mini',\n",
    "                        prompt_template='Extract fields (\"fruit\": <str>, \"color\": <str>, \"flavor\") from the following text, as json: {sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5455a49-eb20-4eab-8392-2ec1410ee4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/bikashg-spencer-group/eval-example/r/call/01956871-87a6-7102-b14d-9e6bee8d69b4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get prediction on one single example as a test.\n",
    "await model_2.predict(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e681c336-9d52-4a99-8ba0-7b2b35bc689d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MultiTaskBinaryClassificationF1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'fruit'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666666666666</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'color'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'flavor'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fruit_name_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666666666666</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0795169671376545</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'MultiTaskBinaryClassificationF1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'fruit'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m0.8\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.6666666666666666\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'color'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'flavor'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'fruit_name_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.6666666666666666\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m1.0795169671376545\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/bikashg-spencer-group/eval-example/r/call/01956871-8bf1-7143-b135-00717f02e91c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MultiTaskBinaryClassificationF1': {'fruit': {'f1': 0.8,\n",
       "   'precision': 0.6666666666666666,\n",
       "   'recall': 1.0},\n",
       "  'color': {'f1': 1.0, 'precision': 1.0, 'recall': 1.0},\n",
       "  'flavor': {'f1': 1.0, 'precision': 1.0, 'recall': 1.0}},\n",
       " 'fruit_name_score': {'correct': {'true_count': 2,\n",
       "   'true_fraction': 0.6666666666666666}},\n",
       " 'model_latency': {'mean': 1.0795169671376545}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(asyncio.run(evaluation.evaluate(model)))\n",
    "# if you're in a Jupyter Notebook, run:\n",
    "await evaluation.evaluate(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de7970-8818-4c20-9841-a19d8e3224b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
